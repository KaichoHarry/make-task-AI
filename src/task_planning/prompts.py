import json
import time
import google.generativeai as genai
from prompts import TASK_GENERATION_SYSTEM_PROMPT

# ==========================================
# è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
BATCH_SIZE = 5  # 1å›ã«å‡¦ç†ã™ã‚‹ACã®æ•°ï¼ˆ5å€‹ç¨‹åº¦ãŒæœ€ã‚‚é«˜å¯†åº¦ã«ãªã‚Šã¾ã™ï¼‰

# 2å›ç›®ä»¥é™ã«è‡ªå‹•æŒ¿å…¥ã™ã‚‹ã€Œã‚¯ã‚®ã‚’åˆºã™ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
REMINDER_PROMPT = """
Great. Now proceed with the next batch of ACs.

âš ï¸ **CRITICAL REMINDERS (DO NOT FORGET):**
1. **Maintain the 4-Layer Structure**: [DB], [BE], [FE], [Test] for EVERY single AC.
2. **Tech Stack**: Next.js (Zod), FastAPI (Pydantic), SQLAlchemy.
3. **Consistency**: Use the same naming conventions as the previous batch.
4. **No Summary**: Do not summarize. Keep the high density.

Here are the next ACs:
"""

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
def generate_tasks_automatically(json_file_path):
    # 1. JSONãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    with open(json_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    all_acs = data.get("acceptance_criteria", [])
    total_acs = len(all_acs)
    print(f"ğŸš€ Total ACs found: {total_acs}")

    # 2. ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ (APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ç­‰ã§è¨­å®šæ¸ˆã¿ã¨ã™ã‚‹)
    model = genai.GenerativeModel(
        model_name="gemini-1.5-pro-latest", # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒåºƒã„ãƒ¢ãƒ‡ãƒ«æ¨å¥¨
        system_instruction=TASK_GENERATION_SYSTEM_PROMPT
    )
    
    # ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹ï¼ˆã“ã‚Œã§æ–‡è„ˆã‚’è¨˜æ†¶ã•ã›ã‚‹ï¼‰
    chat = model.start_chat(history=[])
    
    generated_tasks_log = []

    # 3. ãƒãƒƒãƒå‡¦ç†ãƒ«ãƒ¼ãƒ—
    for i in range(0, total_acs, BATCH_SIZE):
        batch_acs = all_acs[i : i + BATCH_SIZE]
        current_batch_num = (i // BATCH_SIZE) + 1
        print(f"\nProcessing Batch {current_batch_num} (AC {i+1} to {min(i+BATCH_SIZE, total_acs)})...")

        # --- ã“ã“ãŒè‡ªå‹•åŒ–ã®ã‚­ãƒ¢ ---
        if i == 0:
            # åˆå›: æ™®é€šã«ACã‚’æ¸¡ã™
            user_message = f"Here is the first batch of ACs:\n{json.dumps(batch_acs)}"
        else:
            # 2å›ç›®ä»¥é™: ã€Œãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼ã€ï¼‹ã€Œæ¬¡ã®ACã€ã‚’çµåˆã—ã¦æ¸¡ã™
            user_message = f"{REMINDER_PROMPT}\n{json.dumps(batch_acs)}"
        # ------------------------

        try:
            # AIã«é€ä¿¡
            response = chat.send_message(user_message)
            
            # çµæœã‚’è¡¨ç¤ºãƒ»ä¿å­˜ï¼ˆå®Ÿéš›ã¯ã“ã“ã§ãƒ‘ãƒ¼ã‚¹ã—ã¦ä¿å­˜å‡¦ç†ã‚’å…¥ã‚Œã‚‹ï¼‰
            print(f"âœ… Batch {current_batch_num} Complete. Output length: {len(response.text)} chars")
            generated_tasks_log.append(response.text)
            
            # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            time.sleep(2) 

        except Exception as e:
            print(f"âŒ Error in Batch {current_batch_num}: {e}")
            break

    print("\nğŸ‰ All batches processed successfully!")
    return generated_tasks_log

if __name__ == "__main__":
    # å®Ÿè¡Œ
    results = generate_tasks_automatically("login_us001.json")
    
    # å¿…è¦ãªã‚‰çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open("final_high_density_tasks.md", "w", encoding="utf-8") as f:
        f.write("\n\n".join(results))